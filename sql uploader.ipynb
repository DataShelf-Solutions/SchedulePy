{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:05:14.063148900Z",
     "start_time": "2024-09-16T12:05:14.042616900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from SchedulePy.Path import make_directory, current_path_and_path_list\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "current_path, path_list = current_path_and_path_list()\n",
    "datapath = make_directory(str(current_path)+'\\\\Data\\\\')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:05:14.301364Z",
     "start_time": "2024-09-16T12:05:14.294931400Z"
    }
   },
   "id": "cb3cbb12911b23e3",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:05:14.568241900Z",
     "start_time": "2024-09-16T12:05:14.551179800Z"
    }
   },
   "id": "dfde3cba41767e5d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Uploader:\n",
    "    def __init__(self, abspath, conn):\n",
    "        self.abspath = abspath\n",
    "        self.conn = conn\n",
    "        \n",
    "    def create_table(self,db=None):\n",
    "        self.db = db\n",
    "        if not self.db:\n",
    "            raise ValueError('db parameter is required')\n",
    "        self.db_name = self.db.split('.')[0]\n",
    "        self.schema = self.db.split('.')[1]\n",
    "        self.table_name = self.db.split('.')[2]\n",
    "\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(f\"USE [{self.db_name}]\")\n",
    "        print(f\"Switched to database: {self.db_name}\")\n",
    "\n",
    "        # Check if that table already exists\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{ self.table_name}' AND TABLE_SCHEMA = '{self.schema}'\")\n",
    "        table_exists = cursor.fetchone()[0]\n",
    "        if not table_exists:\n",
    "            df = self.__load_file()\n",
    "            # generate SQL column definitions based on DataFrame's dtypes\n",
    "            column_definitions = self.__generate_sql_columns(df)\n",
    "            \n",
    "            print(f\"Columns{column_definitions}\")\n",
    "            return df\n",
    "        \n",
    "        # hidden class method to load the file based on its extension\n",
    "    def __load_file(self):\n",
    "        # mapping of file extensions to pandas loader functions\n",
    "        loaders = {\n",
    "            '.csv': pd.read_csv,\n",
    "            '.xlsx': pd.read_excel,\n",
    "            '.pkl': pd.read_pickle,\n",
    "            '.feather': pd.read_feather\n",
    "            # add more extensions and loaders as needed\n",
    "        }\n",
    "\n",
    "        # extracting the file extension using pathlib\n",
    "        file_extension = Path(self.abspath).suffix.lower()\n",
    "\n",
    "        # get the appropriate loader function or raise an error if unsupported\n",
    "        loader = loaders.get(file_extension)\n",
    "        if loader:\n",
    "            return loader(self.abspath)\n",
    "\n",
    "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "\n",
    "\n",
    "    # hidden class method to generate SQL column definitions from DataFrame\n",
    "    def __generate_sql_columns(self, df):\n",
    "        # mapping pandas dtypes to SQL types\n",
    "        dtype_mapping = {\n",
    "            'int64': 'INT',\n",
    "            'float64': 'FLOAT',\n",
    "            'object': 'NVARCHAR(MAX)',\n",
    "            'datetime64[ns]': 'DATETIME',\n",
    "            'bool': 'BIT',\n",
    "            # add more mappings as necessary\n",
    "        }\n",
    "\n",
    "        # creating the column definitions string\n",
    "        column_definitions = ', '.join([\n",
    "            f\"{col} {dtype_mapping.get(str(dtype), 'NVARCHAR(MAX)')}\"\n",
    "            for col, dtype in df.dtypes.items()\n",
    "        ])\n",
    "\n",
    "        return column_definitions\n",
    "        \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:05:15.121341Z",
     "start_time": "2024-09-16T12:05:15.107989800Z"
    }
   },
   "id": "63d0b66de5d0c92e",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to database: WH_ScoringReports\n",
      "ColumnsAlbum NVARCHAR(MAX), Release Date DATETIME, Sales (Millions) FLOAT, Genre NVARCHAR(MAX), Duration (Minutes) FLOAT, Label NVARCHAR(MAX), Grammy Nominations FLOAT, Critics Score FLOAT, Recording Start DATETIME\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       Album Release Date  Sales (Millions)             Genre  \\\n0  The Dark Side of the Moon   1973-03-01              45.0  Progressive Rock   \n1         Wish You Were Here   1975-09-12              20.0  Progressive Rock   \n2                   The Wall   1979-11-30              30.0        Rock Opera   \n3                       None          NaT               NaN              Rock   \n4                    Animals   1977-01-23              12.0              None   \n\n   Duration (Minutes)     Label  Grammy Nominations  Critics Score  \\\n0                43.0   Harvest                 1.0            9.5   \n1                44.0   Harvest                 NaN            9.2   \n2                81.0  Columbia                 6.0            NaN   \n3                 NaN   Harvest                 1.0            8.7   \n4                41.0      None                 NaN            8.9   \n\n  Recording Start  \n0      1972-06-01  \n1             NaT  \n2      1978-01-01  \n3      1976-04-01  \n4      1976-04-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Album</th>\n      <th>Release Date</th>\n      <th>Sales (Millions)</th>\n      <th>Genre</th>\n      <th>Duration (Minutes)</th>\n      <th>Label</th>\n      <th>Grammy Nominations</th>\n      <th>Critics Score</th>\n      <th>Recording Start</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Dark Side of the Moon</td>\n      <td>1973-03-01</td>\n      <td>45.0</td>\n      <td>Progressive Rock</td>\n      <td>43.0</td>\n      <td>Harvest</td>\n      <td>1.0</td>\n      <td>9.5</td>\n      <td>1972-06-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wish You Were Here</td>\n      <td>1975-09-12</td>\n      <td>20.0</td>\n      <td>Progressive Rock</td>\n      <td>44.0</td>\n      <td>Harvest</td>\n      <td>NaN</td>\n      <td>9.2</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Wall</td>\n      <td>1979-11-30</td>\n      <td>30.0</td>\n      <td>Rock Opera</td>\n      <td>81.0</td>\n      <td>Columbia</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>1978-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>Rock</td>\n      <td>NaN</td>\n      <td>Harvest</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>1976-04-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Animals</td>\n      <td>1977-01-23</td>\n      <td>12.0</td>\n      <td>None</td>\n      <td>41.0</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>8.9</td>\n      <td>1976-04-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to your SQL Server database\n",
    "# conn = pyodbc.connect('Driver={SQL Server};'\n",
    "#                       'Server=10.102.103.104;'\n",
    "#                       'Database=something;')\n",
    "\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=10.195.103.194;'\n",
    "                      'Database=Master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "uploader = Uploader(abspath=r'C:\\Users\\kristinedzneladze\\Desktop\\SchedulePy\\Data\\pnk.feather',conn=conn)\n",
    "uploader.create_table(\"WH_ScoringReports.idk.pinkfloyd\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:05:15.882804200Z",
     "start_time": "2024-09-16T12:05:15.772171200Z"
    }
   },
   "id": "cfd678d9a0860ede",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T10:23:01.751497100Z",
     "start_time": "2024-09-16T10:23:01.668009400Z"
    }
   },
   "id": "260103ca3b771b30",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# conn = pyodbc.connect('Driver={SQL Server};'\n",
    "#                       'Server=10.195.103.194;'\n",
    "#                       'Database=WH_ScoringReports;'\n",
    "#                       'Trusted_Connection=yes;')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:58:52.676634300Z",
     "start_time": "2024-09-16T07:58:52.667108300Z"
    }
   },
   "id": "6280b6c44262941a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generating sample data for a DataFrame about Pink Floyd\n",
    "data = {\n",
    "    'Album': ['The Dark Side of the Moon', 'Wish You Were Here', 'The Wall', np.nan, 'Animals'],\n",
    "    'Release Date': ['1973-03-01', '1975-09-12', '1979-11-30', np.nan, '1977-01-23'],\n",
    "    'Sales (Millions)': [45.0, 20.0, 30.0, np.nan, 12.0],\n",
    "    'Genre': ['Progressive Rock', 'Progressive Rock', 'Rock Opera', 'Rock', np.nan],\n",
    "    'Duration (Minutes)': [43.0, 44.0, 81.0, np.nan, 41.0],\n",
    "    'Label': ['Harvest', 'Harvest', 'Columbia', 'Harvest', np.nan],\n",
    "    'Grammy Nominations': [1, np.nan, 6, 1, np.nan],\n",
    "    'Critics Score': [9.5, 9.2, np.nan, 8.7, 8.9],\n",
    "    'Recording Start': ['1972-06-01', np.nan, '1978-01-01', '1976-04-01', '1976-04-01']\n",
    "}\n",
    "\n",
    "# Converting date columns to datetime\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'], errors='coerce')\n",
    "data['Recording Start'] = pd.to_datetime(data['Recording Start'], errors='coerce')\n",
    "\n",
    "# Creating the DataFrame\n",
    "pink_floyd_df = pd.DataFrame(data)\n",
    "pink_floyd_df.to_pickle(datapath+'pnk.pkl')\n",
    "pink_floyd_df.to_excel(datapath+'pnk.xlsx')\n",
    "pink_floyd_df.to_csv(datapath+'pnk.csv')\n",
    "pink_floyd_df.to_feather(datapath+'pnk.feather')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:58:53.373026700Z",
     "start_time": "2024-09-16T07:58:53.304672500Z"
    }
   },
   "id": "b52f96d18296f7d6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33c0ac0878e69b37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
